# Trademark Similarity Detection System

This repository contains the full implementation of an AI-powered trademark similarity detection system developed as part of the Applied Data Science MSc project at the University of Manchester. This project is a hybrid trademark similarity search tool that supports both text-based and image-based queries. Built using Streamlit, it combines natural language processing, computer vision, and OCR to detect potential trademark conflicts across verbal and visual modalities.

## Overview

The system analyses both textual and visual similarities between new trademark submissions and existing entries in a PostgreSQL registry. It uses a hybrid approach combining:

- **Textual similarity**: BERT embeddings, RapidFuzz, and phonetic encoding (Double Metaphone)
- **Visual similarity**: ResNet and pHash image features
- **Risk scoring**: A rubric-based composite score classifying matches as Low, Medium, or High risk

## Features

- OCR support for logo images (EasyOCR)
- Multimodal similarity scoring (text + image)
- Batch querying for scalable processing
- CSV report generation with detailed scoring breakdowns
- Modular Python codebase for easy integration and updates

## Project Structure
The project contains two main pipelines: image search pipeline and text search pipeline. Both are exclusive and run independently. Future work includes combining these two pipelines into a single architecture. Image similarity has a frontend, while text similarity is an executable Python script.
```
.Image Similarity Files
├── app.py                         # Streamlit frontend app (main UI and logic)
├── ocr_functions.py               # OCR and text similarity scoring
├── db_utils.py                    # Fetch images from PostgreSQL
├── hybrid_feature_index_build.py  # Generate CLIP + ResNet embeddings for dataset
├── hybrid_feature_index_search.py # CLI tool for testing hybrid search
├── marks_trademarks_images.py     # Export base64 images to decoded_images/ nad write image_index.csv
├── decoded_images/                # Folder of preprocessed trademark images (will be generated from DB by marks_trademarks_images.py)
├── image_index.csv                # Mapping between image filenames and mark IDs (will be generated by hybrid_feature_index_build.py)
├── clip_features.npy              # CLIP embeddings (will be generated by hybrid_feature_index_build.py)
├── resnet_features.npy            # ResNet embeddings (will be generated by hybrid_feature_index_build.py)
├── requirements.txt               # List of Python dependencies

Text Similarity Files
├── trademark_check.py                         # Executable Python code for text similarity 
```
## Data Requirements
This project depends on a PostgreSQL database containing trademark metadata and base64-encoded images.

## Setup
pip install -r requirements.txt

**External requirement:**

- [wkhtmltopdf](https://wkhtmltopdf.org/) — required by `pdfkit` for PDF report generation
  - On Ubuntu: `sudo apt install wkhtmltopdf`
  - On Windows: Download installer from official site

## For running only text similarity, run the below code
python trademark_check.py -name "Example Name" -country GB -class trademark_class

## For running image similarity, follow the instructions below:
Before using the app:

1. Run `marks_trademarks_images.py` to export images to `decoded_images/`
2. Run `hybrid_feature_index_build.py` to generate image feature embeddings
3. Launch the app with:

```bash
streamlit run app.py
```

---

## Methods Summary

- **Text Similarity**:

  - Sentence-BERT (semantic)
  - RapidFuzz (lexical)
  - Double Metaphone (phonetic)

- **Image Similarity**:

  - CLIP (semantic vision)
  - ResNet-50 (structural features)
  - Cosine similarity + weighted aggregation

- **Output**: Combined PDF report with query image, OCR results, and visual/textual matches
- 

---
